llm_provider = "mistral"  # Options: "mistral", "gemini", "openai"

mistral_api_key = "x5XqMRgUH0juaahAK6plZMjU6ASGNAGs"      # Your Mistral API key (optional)

gemini_api_key = ""       # Your Gemini API key (optional)

openai_api_key = ""       # Your OpenAI API key (optional)

local_model_url = "http://localhost:11434"  # URL for local model (if used)